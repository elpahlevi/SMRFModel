{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random search cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, gdal_array\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "gdal.UseExceptions()\n",
    "gdal.AllRegister()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all training raster dataset\n",
    "tr_stacked = gdal.Open('trainingImage/stacked_indicies_kampar.tif', gdal.GA_ReadOnly)\n",
    "tr_smi = gdal.Open('trainingImage/smi_training_1.tif', gdal.GA_ReadOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (176810, 15) and Y shape (176810,)\n"
     ]
    }
   ],
   "source": [
    "#convert to array for training data\n",
    "stacked_zeros = np.zeros((tr_stacked.RasterYSize, tr_stacked.RasterXSize, tr_stacked.RasterCount),\n",
    "                            gdal_array.GDALTypeCodeToNumericTypeCode(tr_stacked.GetRasterBand(1).DataType))\n",
    "for a in range(stacked_zeros.shape[2]):\n",
    "    stacked_zeros[:, :, a] = tr_stacked.GetRasterBand(a + 1).ReadAsArray()\n",
    "smi = tr_smi.GetRasterBand(1).ReadAsArray().astype(np.float32)\n",
    "smi_masked = np.ma.masked_where(smi == 0, smi)\n",
    "#let's create feature and label array of training data\n",
    "x = stacked_zeros[smi > 0, :] #feature\n",
    "y = smi[smi > 0] #label\n",
    "print('X shape {x} and Y shape {y}'.format(x = x.shape, y = y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape : (132607, 15)\n",
      "Training labels shape : (132607,)\n",
      "Testing features shape (44203, 15)\n",
      "Testing labels shape: (44203,)\n"
     ]
    }
   ],
   "source": [
    "#split our data to train and test data by 75% and 25%\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)\n",
    "print('Training features shape :', x_train.shape)\n",
    "print('Training labels shape :', y_train.shape)\n",
    "print('Testing features shape', x_test.shape)\n",
    "print('Testing labels shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [1, 7, 14, 21, 28, 35, 42, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [100, 125, 150, 175, 200, 225, 250]}\n"
     ]
    }
   ],
   "source": [
    "#Random search cross validation parameters\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 250, num = 7)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(1, 42, num = 7)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {\n",
    "    'n_estimators'   : n_estimators,\n",
    "    'max_features'   : max_features,\n",
    "    'max_depth'     : max_depth,\n",
    "    'min_samples_split' : min_samples_split,\n",
    "    'min_samples_leaf' : min_samples_leaf,\n",
    "    'bootstrap' : bootstrap\n",
    "}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a base model\n",
    "rfReg = RandomForestRegressor(random_state = 42)\n",
    "#initiate random search model\n",
    "rf_random = RandomizedSearchCV(estimator = rfReg, param_distributions = random_grid, \n",
    "                               n_iter = 30, scoring='neg_mean_absolute_error', cv = 3, verbose = 2, random_state = 42, n_jobs = -1, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 42.9min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed: 97.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fals...\n",
       "                   iid='deprecated', n_iter=30, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [1, 7, 14, 21, 28, 35, 42,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 125, 150, 175,\n",
       "                                                         200, 225, 250]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the grid\n",
    "rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False,\n",
      " 'max_depth': None,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "#print the best params\n",
    "pprint(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    rsq = r2_score(test_labels, predictions)\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    print('R Squared score = {r}'.format(r = rsq))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.0786 degrees.\n",
      "Accuracy = 83.55%.\n",
      "R Squared score = 0.5506993815454889\n"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "grid_accuracy = evaluate(best_random, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
